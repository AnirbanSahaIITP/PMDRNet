### PMDRNet

## Additional References

**Dataset**

    1. BSD400: D. Martin, C. Fowlkes, D. Tal and J. Malik, "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics," Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, Vancouver, BC, Canada, 2001, pp. 416-423 vol.2.
    2. CBSD432: S. Roth and M. Black, “Fields of experts,” International Journal of Computer Vision, vol. 82, pp. 205–229, 04 2009.
    3. Set5: M. Bevilacqua, A. Roumy, C. M. Guillemot, and M.-L. Alberi-Morel, “Low-complexity single-image super-resolution based on nonnegative neighbor embedding,” in British Machine Vision Conference, 2012.
    4. Set14: R. Zeyde, M. Elad, and M. Protter, “On single image scale-up using sparse-representations,” in Curves and Surfaces, J.-D. Boissonnat, P. Chenin, A. Cohen, C. Gout, T. Lyche, M.-L. Mazure, and L. Schumaker, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2012, pp. 711–730.
    5. BSD68: S. Roth and M. Black, “Fields of experts: a framework for learning image priors,” in 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), vol. 2, 2005, pp. 860–867 vol. 2.
    6. CBSD68: S. Roth and M. Black, “Fields of experts,” International Journal of Computer Vision, vol. 82, pp. 205–229, 04 2009.
    7. SIDD: A. Abdelhamed, S. Lin, and M. S. Brown, “A high-quality denoising dataset for smartphone cameras,” in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 1692–1700.
    8. POLYU: J. Xu, H. Li, Z. Liang, D. Zhang, and L. Zhang, “Real-world noisy image denoising: A new benchmark,” CoRR, vol. abs/1804.02603, 2018.
    9. Nam: S. Nam, Y. Hwang, Y. Matsushita, and S. J. Kim, “A holistic approach to cross-channel image noise modeling and its application to image denoising,” in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 1683–1691.

**Comparing Methodologies**

     1. BM3D: K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, “Image denoising by sparse 3-d transform-domain collaborative filtering,” IEEE Transactions on Image Processing, vol. 16, no. 8, pp. 2080–2095, 2007.
     2. WNNM: S. Gu, L. Zhang, W. Zuo, and X. Feng, “Weighted nuclear norm minimization with application to image denoising,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 2862–2869.
     3. DnCNN: K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, “Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising,” IEEE transactions on image processing, vol. 26, no. 7, pp. 3142–3155, 2017.
     4. BUIFD: M. El Helou and S. Susstrunk, “Blind universal bayesian image denoising with gaussian noise level learning,” IEEE Transactions on Image Processing, vol. 29, pp. 4885–4897, 2020.
     5. ComplexNet: Y. Quan, Y. Chen, Y. Shao, H. Teng, Y. Xu, and H. Ji, “Image denoising using complex-valued deep cnn,” Pattern Recognition, vol. 111, p. 107639, 03 2021.
     6. SWINIR: J. Liang, J. Cao, G. Sun, K. Zhang, L. Van Gool, and R. Timofte, “Swinir: Image restoration using swin transformer,” in Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 1833–1844.
     7. Restormer: S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, and M.-H. Yang, “Restormer: Efficient transformer for high-resolution image restoration,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 5728–5739.
     8. ZSN2N: W. Dong, L. Zhang, G. Shi, and X. Li, “Nonlocally centralized sparse representation for image restoration,” IEEE Transactions on Image Processing, vol. 22, no. 4, pp. 1620–1630, 2013.
     9. NIFBGDNet: R. K. Thakur and S. K. Maji, “Multi scale pixel attention and feature extraction based neural network for image denoising,” Pattern Recognition, vol. 141, p. 109603, 2023.
    10. DRANet: W. Wu, S. Liu, Y. Xia, and Y. Zhang, “Dual residual attention network for image denoising,” Pattern Recognition, vol. 149, p. 110291, 2024.
    11. SSAMan: A. Zafar, D. Aftab, R. Qureshi, X. Fan, P. Chen, J. Wu, H. Ali, S. Nawaz, S. Khan, and M. Shah, “Single stage adaptive multi-attention network for image restoration,” IEEE Transactions on Image Processing, vol. 33, pp. 2924–2935, 2024.
    12. CasaPuNet: J. Huang, X. Liu, Y. Pan, X. He, and C. Ren, “Casapunet: Channel affine self-attention- based progressively updated network for real image denoising,” IEEE Transactions on Industrial Informatics, vol. 19, no. 8, pp. 9145–9156, 2023.
    13. GrencNet: Y. Pan, C. Ren, X. Wu, J. Huang, and X. He, “Real image denoising via guided residual estimation and noise correction,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 33, no. 4, pp. 1994–2000, 2023.
    14. APD-Nets: B. Jiang, Y. Lu, J. Wang, G. Lu, and D. Zhang, “Deep image denoising with adaptive priors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 32, no. 8, pp. 5124–5136, 2022.
    15. UFormer: Z. Wang, X. Cun, J. Bao, W. Zhou, J. Liu, and H. Li, “Uformer: A general u-shaped transformer for image restoration,” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2022, pp. 17 683–17 693.
    16. MPRNet: S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M.-H. Yang, and L. Shao, “Multi-stage progressive image restoration,” in CVPR, 2021.
    17. RIDNet: S. Anwar and N. Barnes, “Real image denoising with feature attention,” in 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 3155–3164.
    18. CBDNet: S. Guo, Z. Yan, K. Zhang, W. Zuo, and L. Zhang, “Toward convolutional blind denoising of real photographs,” in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 1712–1722.
    19. FFDNet: K. Zhang, W. Zuo, and L. Zhang, “Ffdnet: Toward a fast and flexible solution for cnn-based image denoising,” IEEE Transactions on Image Processing, vol. 27, no. 9, pp. 4608–4622, 2018.
